plot() + scale_shape_discrete()
cluster_analysis(datascores,
n = 4,
method = "hkmeans") %>%
plot() + scale_shape_manual(1)
?scale_shape
cluster_analysis(datascores,
n = 4,
method = "hkmeans") %>%
plot() + scale_shape()
cluster_analysis(datascores,
n = 2,
method = "hkmeans")
cluster_analysis(datascores, n = 2, method = "hkmeans")
cluster_analysis(datascores, n = 4, method = "hkmeans")
View(datascores)
View(data_latent)
# ---- annex_clusters ----------------------------------------------------------
# data_latent %>% check_clusterstructure()
# data_latent %>% n_clusters() %>% plot()
# cluster_analysis(datascores, n = 2, method = "hkmeans")
cluster_analysis(data_latent, n = 4, method = "hkmeans") %>% plot()
cluster_analysis(data_latent, n = 4, method = "hkmeans")
# ---- annex_clusters ----------------------------------------------------------
# data_latent %>% check_clusterstructure()
# data_latent %>% n_clusters() %>% plot()
# cluster_analysis(datascores, n = 2, method = "hkmeans")
cluster_analysis(data_latent, n = 2, method = "hkmeans") %>% plot()
cluster_analysis(data_latent, n = 2, method = "hkmeans")
# ---- annex_clusters ----------------------------------------------------------
# data_latent %>% check_clusterstructure()
# data_latent %>% n_clusters() %>% plot()
# cluster_analysis(datascores, n = 2, method = "hkmeans")
cluster_analysis(data_latent, n = 4, method = "hkmeans") %>% plot()
data_latent %>% select(-group, -subject_nr) %>%
gather(key = variable, value = value, -cluster)%>%
group_by(cluster, variable) %>%
summarise(mean = mean(value),
sd = sd(value),
min = min(value),
max = max(value))
View(descript)
# ---- k_means -----------------------------------------------------------------
data_kmeans %>%
fviz_cluster(
data_scale,
geom = "point",
repel = TRUE,
ellipse.type = "convex",
shape = "circle", pointsize = 1.2,
main =
"Representation des clusters selon les deux composantes principales",
xlab = "Dimension 1 (40.7%)",
ylab = "Dimension 2 (18.4%)",
) +
theme_bw(base_size = 14, base_family = "serif")
View(data_scale)
View(data)
View(data_analysis)
View(data_analysis)
citr:::insert_citation()
source("~/aphantasia_project/zc_scripts/aphantasia_source.R")
# ---- lollipop ----------------------------------------------------------------
data_latent %>%
mutate(across(-cluster, ~ rescale(.x, to = c(0,1))),) %>%
gather(key = variable, value = value, -cluster) %>%
group_by(variable, cluster) %>%
summarise(mean = mean(value)) %>%
ggdotchart(
x = "cluster",
y = "mean",
group = "variable",
color = "variable", size = 1, dot.size = 3,
palette = "aas",
add = "segment",
position = position_dodge(.5),
sorting = "descending",
#facet.by = "cluster",
rotate = TRUE,
#legend = "none",
ggtheme = theme_bw(base_size = 14, base_family = "serif"),
xlab = "Fonctions Cognitives",
ylab = "Moyennes",
# title =
#   "Scores aux differentes fonctions cognitives en fonction des clusters"
) +
# geom_smooth(aes(group = cluster, color = cluster),size = .8) +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
)
# ---- lollipop ----------------------------------------------------------------
data_latent %>%
mutate(across(-cluster, ~ rescale(.x, to = c(0,1))),) %>%
gather(key = variable, value = value, -cluster) %>%
group_by(variable, cluster) %>%
summarise(mean = mean(value)) %>%
ggdotchart(
x = "cluster",
y = "mean",
group = "variable",
color = "variable", size = 1, dot.size = 3,
palette = "aas",
add = "segment",
position = position_dodge(.5),
sorting = "descending",
#facet.by = "cluster",
rotate = TRUE,
#legend = "none",
ggtheme = theme_bw(base_size = 14, base_family = "serif"),
xlab = "Cluster",
ylab = "Moyennes",
# title =
#   "Scores aux differentes fonctions cognitives en fonction des clusters"
) +
# geom_smooth(aes(group = cluster, color = cluster),size = .8) +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
)
# loading
shelf(trackdown)
# update the GDoc with the Rmds
pdate_file("1_intro.Rmd",
gfile = "1_introduction",
gpath = "M2 EMC - Aphantasia/manuscrit",
hide_code = TRUE,)
# update the GDoc with the Rmds
update_file("1_intro.Rmd",
gfile = "1_introduction",
gpath = "M2 EMC - Aphantasia/manuscrit",
hide_code = TRUE,)
# update the GDoc with the Rmds
upload_file("1_intro.Rmd",
gfile = "1_introduction",
gpath = "M2 EMC - Aphantasia/manuscrit",
hide_code = TRUE,)
upload_file("2_methode.Rmd",
gfile = "2_methode",
gpath = "M2 EMC - Aphantasia/manuscrit",
hide_code = TRUE,)
upload_file("3_resultats.Rmd",
gfile = "3_resultats",
gpath = "M2 EMC - Aphantasia/manuscrit",
hide_code = TRUE,)
upload_file("4_discussion.Rmd",
gfile = "4_discussion",
gpath = "M2 EMC - Aphantasia/manuscrit",
hide_code = TRUE,)
upload_file("5_annexes.Rmd",
gfile = "5_annexes",
gpath = "M2 EMC - Aphantasia/manuscrit",
hide_code = TRUE,)
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
?lib_paths
citation()
print(.packages())
?`utils-package`
library(help = "utils")
# packages
shelf(
easystats,  # modelling, visualization and reporting ecosystem
ggpubr,     # publication plots
ggradar,    # radar charts
cluster,     # self-explanatory
factoextra,
)
?ggdotchart
shelf(pandoc)
citation(pandoc)
?pandoc
citation("pandoc)
citation("pandoc")
citation("pandoc")
citr:::insert_citation()
citation("knitr")
citr:::insert_citation()
citr:::insert_citation()
?lib_startup
print(.packages())
report(.packages())
report(sessionInfo())
# ---- setup -------------------------------------------------------------------
# packages
shelf(
ggpubr,     # publication plots
ggradar,    # radar charts
cluster,     # self-explanatory
factoextra,
)
# global theme
theme_set(theme_bw(base_size = 14, base_family = "serif"))
# random seed
set.seed(14051998)
# Simulation des donnees
# definition des variables et groupes
# groupe non-aphantasique
Non_A <- data.frame(
name = c("OSIQ_O", "OSIQ_S", "VVIQ",
"Raven", "Simili", "Wason",
"Empan_MDT", "WCST", "Lecture",
"Corsi","MRT", "SRI"),
mean = c(54.6,  46.2,  63.8,
20.9,  37.8,  32.2,
6.43,  32.1,  50.2,
5.81,  16.5,  35.7),
sd = c(8.45,  9.54,  9.67,
5.34,  4.25,  3.78,
2.12,  5.32,  8.89,
1.87,  3.54,  6.23),
group = ("Non_A") %>% factor(),
n_subjects = 200
)
# groupe aphantasique
Aph <- data.frame(
name = c("OSIQ_O", "OSIQ_S", "VVIQ",
"Raven", "Simili", "Wason",
"Empan_MDT", "WCST", "Lecture",
"Corsi","MRT", "SRI"),
mean = c(32.5,  58.9,  30.2,
23.6,  42.2,  36.1,
7.53,  33.8,  48.4,
6.8,   18.2,  38.5),
sd = c(8.45,  9.54,  9.67,
4.24,  6.15,  3.47,
1.45,  2.62,  9.67,
1.65,  5.78,  8.21),
group = ("Aph") %>% factor(),
n_subjects = 200
)
# dataset fusionné
variables <- bind_rows(Aph,Non_A)
rm(Aph,Non_A)
# liens variables-capacites cognitives
fmodel <- matrix(c ( .8,   0,  0,  0,  0, # OSIQ-O = img objet
0,  .9,  0,  0,  0, # OSIQ-S = img spatiale
.9,   0,  0,  0,  0, # VVIQ = img objet
.1,  .3, .8,  0,.05, # Raven = raisonnmt > img s/o > flex
-.2,   0, .6,  0, .1, # Simili = raisonnmt >  flex
-.1,   0, .3,  0,  0, # Wason = raisonnmt
0,   0,  0, .8,  0, # Empan = MDT
-.1,   0, .2,  0, .6, # WCST = Flex > raisonnmt
.4,   0, .6,  0,  0, # Lecture = img objet > raisonnmt
.1,  .7,  0, .8,  0, # Corsi = MDT > img s
.2, .85,  0,  0,  0, # MRT = img s
.1,  .9,  0,  0,  0  # SRI = img s
),
nrow=12, ncol=5, byrow=TRUE)
# liens entre capacites cognitives
effect <- matrix(c (  1,-.1,-.1, .2,  0, # img o
-.1,  1, .3, .2,  0, # img s
-.1, .3,  1,  0, .2, # raisonnmt
.2, .2,  0,  1,  0, # MDT
0,  0, .2,  0,  1  # flex
),
nrow=5, ncol=5, byrow=TRUE)
# fonction de simulation
simulation <- function(variables, fmodel, effect) {
### preparatifs ###
n_variables <- dim(fmodel)[1] # notre nb de mesures/variables (rows)
n_skills <- dim(fmodel)[2]    # les capacites sous-jacentes evaluees (columns)
# matrice de poids des erreurs
errorweight <- (1 - diag(fmodel %*% t(fmodel))) %>%
abs() %>%   # necessaire pour la racine carree
sqrt() %>%  # doit avoir des arguments positifs
diag()      # recree une matrice diagonalisee
# initialisation d'un dataframe vide
data <- data.frame()
### simulation ###
for (i in levels(variables$group)){   # on simule separement chaque groupe
var_group = variables %>% filter(group == i) # donnees du groupe isolees
n_subjects = var_group$n_subjects[1]         # nb de sujets dans le groupe
group = i                                    # nom du groupe
# generation de scores aleatoires normaux pour chaque capacite cognitive
randomscores <- matrix(rnorm(n_subjects * (n_skills)),
nrow = n_subjects,
ncol = n_skills)
# ponderation par la matrice d'effets = les scores sont desormais correles
# entre eux
skillscores <- randomscores %*% effect
# genere les valeurs standardisees des mesures/variables grace a fmodel
observedscores <- skillscores %*% t(fmodel)
# generation d'erreurs normales pour chaque mesure/variable
randomerror <- matrix(rnorm(n_subjects * (n_variables)),
nrow = n_subjects,
ncol = n_variables)
# ponderation par notre matrice de poids des erreurs
error <- randomerror %*% errorweight
# nos mesures effectives = les valeurs reeles + une erreur standard
measures <- observedscores + error
# on cree un dataframe avec le nom de groupe
data_group <- data.frame(measures) %>%
mutate(Group = group %>% factor())
# ajout des valeurs reeles de moyenne et d'ecart-type pour chaque variable
# et renommage
for (i in 1:length(var_group$name)){
data_group[,i] = data_group[,i]*var_group$sd[i] + var_group$mean[i]
colnames(data_group)[i] = var_group$name[i]
}
# fusion avec le dataframe complet
data <- bind_rows(data,data_group)
}
# ajout d'id individuels et stats demographiques
n = length(data[,1])  # nombre total de participants
data <- data %>%
mutate(Subject_nr = row_number() %>% as.character(),
Sex = (c("H","F") %>% rep(times = n/2) %>% factor()),
Age = seq(from = 16, to = 55, by = 1) %>% sample(size = n,
replace = TRUE)
) %>%
relocate(Subject_nr)
# mission accomplished!
return(data)
}
# la fonction est donc clefs en main
data <- simulation(variables,fmodel,effect)
# nettoyage de l'environnement (considérations écologiques)
rm(variables, fmodel, effect)
# Pré-traitement
# on crée un dataset avec les scores uniquement
datascores <- data %>% select(-c(Subject_nr, Group, Sex, Age))
# Analyses
# le dataset réduit à 3 facteurs contre 12 initialement
data_latent <-
factor_analysis(datascores,
rotation = "cluster",
n = 3,
sort = TRUE,
standardize = TRUE) %>%
predict(names = c("Imagerie Spatiale",
"Imagerie Objet",
"Raisonnement"))
# ajout des clusters identifiés
data_latent$cluster <-
cluster_analysis(datascores, n = 4, method = "hkmeans") %>%
predict() %>%
as.factor()
str(data)
report(data)
report(data) %>% as.data.frame() %>% view()
dir.create("./outputs/plots",
recursive = TRUE,
)
if (
!dir.exists("./outputs/plots")
)
dir.create("./outputs/plots",
recursive = TRUE,
)
# saving the plot
if (!dir.exists("./z_plots")) dir.create(
"./z_plots",
recursive = TRUE,
)
?ggsave
# creating a folder for plots
if (!dir.exists("./z_plots")) dir.create(
path = "./z_plots",
recursive = TRUE,
)
# creating a folder for plots
if (!dir.exists("./z_plots")) dir.create(
path = "./z_plots",
recursive = TRUE,
)
# creating a folder for plots
if (
!dir.exists("./z_plots")) dir.create(
path = "./z_plots",
recursive = TRUE,
)
# creating a folder for plots
if (
!dir.exists("./z_plots")
) dir.create(
path = "./z_plots",
recursive = TRUE,
)
# creating a folder for plots
if (
!dir.exists("./z_plots")
) dir.create(
path = "./z_plots",
recursive = TRUE,
)
# my ggplot2 structure
data %>%
ggplot(
# variables
aes(
x = x_axis,
y = y_axis,
group = grouping_variable,
fill = grouping_variable,
),
# as it says :
other_options(),
) +
# my favourite geoms
geom_density() +
geom_violin() +
geom_boxplot() +
geom_jitter() +
geom_smooth() +
geom_point() +
other_geoms() +
# other functions
stat_compare_means() +
stat_summary() +
other_functions()
?stat_compare_means
??scatter3D
# adding clusters belonging to data
data <-
data %>%
mutate(
# analysis
cluster =
cluster_analysis(
n = "auto",
method = "hkmeans",
) %>%
predict() %>%
as.factor()
) %>%
predict() %>%
?ggdotchart
#  add packages to a temporary file to feed Zotero and citr
knitr::write_bib(
# package list
x = c(
# all packages
# .packages(),
# or individual packages
# that_forgotten_package,
parameters
),
# output .bib
file = "packages.bib",
)
#  add packages to a temporary file to feed Zotero and citr
knitr::write_bib(
# package list
x = c(
# all packages
# .packages(),
# or individual packages
# that_forgotten_package,
"parameters"
),
# output .bib
file = "packages.bib",
)
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
# loading the package
shelf(trackdown)
# update the GDoc with the Rmds
update_file(
"1_intro.Rmd",
gfile = "1_introduction",
gpath = "M2 EMC - Aphantasia/manuscrit",
hide_code = TRUE,
)
# update the GDoc with the Rmds
update_file(
"1_intro.Rmd",
gfile = "1_introduction",
gpath = "M2 EMC - Aphantasia/manuscrit_aphantasia",
hide_code = TRUE,
)
update_file(
"2_methode.Rmd",
gfile = "2_methode",
gpath = "M2 EMC - Aphantasia/manuscrit_aphantasia",
hide_code = TRUE,
)
update_file(
"3_resultats.Rmd",
gfile = "3_resultats",
gpath = "M2 EMC - Aphantasia/manuscrit_aphantasia",
hide_code = TRUE,
)
update_file(
"4_discussion.Rmd",
gfile = "4_discussion",
gpath = "M2 EMC - Aphantasia/manuscrit_aphantasia",
hide_code = TRUE,
)
update_file(
"5_annexes.Rmd",
gfile = "5_annexes",
gpath = "M2 EMC - Aphantasia/manuscrit_aphantasia",
hide_code = TRUE,
)
